{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:16:21.792144Z",
     "start_time": "2024-12-19T08:16:21.789513Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.1.5. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81a58c",
   "metadata": {},
   "source": [
    "##### 1. We can explore the connection between exponential families and softmax in some more depth\n",
    "\n",
    "1. Compute the second derivative of the cross-entropy loss $l(\\mathbf{y},\\hat{\\mathbf{y}})$ for softmax.\n",
    "2. Compute the variance of the distribution given by $\\mathrm{softmax}(\\mathbf{o})$ and show that it matches the second derivative computed above.\n",
    "\n",
    "**我们可以更深入地探讨指数族与 softmax 之间的联系**\n",
    "\n",
    "1. 计算 softmax 的交叉熵损失 $l(\\mathbf{y},\\hat{\\mathbf{y}})$ 的二阶导数。\n",
    "2. 计算由 $\\mathrm{softmax}(\\mathbf{o})$ 给出的分布的方差，并证明它与上述计算的二阶导数相匹配。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715bfac",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1.  $$l(\\mathbf{y},\\hat{\\mathbf{y}}) =\\log\\sum_{k=1}^q\\exp(o_k)-\\sum_{j=1}^qy_jo_j.$$\n",
    "\n",
    "$$\\partial_{o_j}l(\\mathbf{y},\\hat{\\mathbf{y}})=\\frac{\\exp(o_j)}{\\sum_{k=1}^q\\exp(o_k)}-y_j=\\mathrm{softmax}(\\mathbf{o})_j-y_j.$$\n",
    "\n",
    "$$\\frac{\\partial^2 l(\\mathbf{y},\\hat{\\mathbf{y}})}{\\partial o_j^2}=\\frac{\\exp(o_j)\\sum_{k=1}^q\\exp(o_k)-(\\exp(o_j))^2}{(\\sum_{k=1}^q\\exp(o_k))^2}=\\mathrm{softmax}(\\mathbf{o})_j - (\\mathrm{softmax}(\\mathbf{o})_j)^2$$\n",
    "\n",
    "2.  假设 $\\mathbf{y}$ 是一个独热向量。 $P(\\mathbf{y}_i=1)=\\mathrm{softmax}(\\mathbf{o})_j, P(\\mathbf{y}_i=0)=1-\\mathrm{softmax}(\\mathbf{o})_j$ 。 那么 $\\mathbf{y}$ 遵循由 $\\mathrm{softmax}(\\mathbf{o})$ 给出的分布。\n",
    "\n",
    "$$E(\\mathbf{y}_j)=\\mathrm{softmax}(\\mathbf{o}_j)$$\n",
    "\n",
    "$$E(\\mathbf{y}_j^2)=\\mathrm{softmax}(\\mathbf{o}_j)$$\n",
    "\n",
    "$$Var(\\mathbf{y}_j)=\\mathrm{softmax}(\\mathbf{o})_j - (\\mathrm{softmax}(\\mathbf{o})_j)^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c7690",
   "metadata": {},
   "source": [
    "##### 2. Assume that we have three classes which occur with equal probability, i.e., the probability vector is $(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$.\n",
    "\n",
    "1. What is the problem if we try to design a binary code for it?\n",
    "2. Can you design a better code? Hint: what happens if we try to encode two independent observations? What if we encode $n$ observations jointly?\n",
    "\n",
    "**假设我们有三个类，它们的发生概率相等，即概率向量为 $(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$**\n",
    "\n",
    "1. 如果我们尝试为它设计一个二进制代码，问题是什么？\n",
    "2. 你能设计一个更好的代码吗？提示：如果我们尝试对两个独立的观察进行编码，会发生什么？如果我们联合编码 $n$ 个观察呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e366baf",
   "metadata": {},
   "source": [
    "答：当处理具有相等概率的三个类时，即每个类的概率为 $\\frac{1}{3}$，尝试使用二进制编码（每位可以表示 2 个状态：0 或 1）直接为每个类别分配一个唯一的代码会遇到一些问题。这是因为二进制系统天然适合于 2 的幂次的数量的状态表示（如 2, 4, 8, 16...），而对于非 2 的幂次数量的状态，比如这里的 3 个类，就不是那么直观了。\n",
    "\n",
    "1. 使用二进制编码的问题\n",
    "\n",
    "如果试图直接用二进制编码这三个类，最简单的方法是为每个类分配两个比特位，这样我们可以得到以下编码：\n",
    "\n",
    "- 类 1: 00\n",
    "- 类 2: 01\n",
    "- 类 3: 10\n",
    "\n",
    "这里没有使用到 \"11\" 这个编码，因为只需要 3 种状态。这样做虽然可行，但并不是最优的，因为它浪费了一个编码，并且平均每个符号需要 2 比特来表示，而理论上我们希望尽可能接近信息论中的最小期望长度。\n",
    "\n",
    "2. 设计更好的编码方案\n",
    "\n",
    "为了设计更有效的编码，我们可以考虑联合编码多个观察结果。通过一次编码多个观察值而不是单个观察值，我们可以更好地利用二进制系统的特性，从而减少整体所需的比特数。\n",
    "\n",
    "_联合编码两个独立的观察_\n",
    "\n",
    "如果我们同时对两个观察进行编码，共有 $3 \\times 3 = 9$ 种可能的结果组合。这正好可以用 4 个比特来表示（$2^4 = 16$，有足够多的编码空间），并且不会浪费任何编码。因此，我们可以创建一个编码表，将每一对观察映射到一个唯一的 4 比特字符串上，这样每个符号的平均比特数为 $4/2 = 2$ 比特，与之前相同，但是我们已经优化了编码效率，因为我们充分利用了所有可用的编码。\n",
    "\n",
    "_联合编码 $n$ 个观察_\n",
    "\n",
    "对于 $n$ 个观察的情况，我们可以进一步优化。当我们增加每次编码的观察数量时，我们可以找到更接近理想情况的编码方式。例如，对于 3 个观察，有 $3^3 = 27$ 种可能的结果，这仍然可以用 5 比特来表示（$2^5 = 32$），这意味着我们可以有效地表示这些组合而不浪费太多编码空间。\n",
    "\n",
    "一般地，如果我们联合编码 $n$ 个观察，那么总共有 $3^n$ 种可能的组合。我们需要找到最小的 $m$ 使得 $2^m \\geq 3^n$，然后用 $m$ 比特来编码这些组合。随着 $n$ 的增加，每个符号的平均比特数将会逐渐接近理论上的最小值，即每个符号的熵 $H(X) = -\\sum p(x) \\log_2(p(x))$，对于均匀分布来说，这是 $-3 \\times (\\frac{1}{3})\\log_2(\\frac{1}{3}) = \\log_2(3)$ 比特/符号。\n",
    "\n",
    "实际上，通过联合编码更多的观察，我们可以无限接近这个极限，尽管在实际应用中，考虑到解码复杂度等因素，通常会选择一个合适的 $n$ 值来平衡编码效率和实现复杂度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7fc0b",
   "metadata": {},
   "source": [
    "##### 3. When encoding signals transmitted over a physical wire, engineers do not always use binary codes. For instance, [PAM-3](https://en.wikipedia.org/wiki/Ternary_signal) uses three signal levels $\\{-1, 0, 1\\}$ as opposed to two levels $\\{0, 1\\}$. How many ternary units do you need to transmit an integer in the range $\\{0, \\ldots, 7\\}$? Why might this be a better idea in terms of electronics?\n",
    "\n",
    "在通过物理电缆传输信号时，工程师并不总是使用二进制代码。例如，PAM-3 使用三个信号级别 $\\{-1, 0, 1\\}$ 而不是两个级别 $\\{0, 1\\}$ 。要在范围 $\\{0, \\ldots, 7\\}$ 内传输一个整数，您需要多少个三元单位？从电子学的角度来看，这为什么可能是一个更好的主意？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6296032",
   "metadata": {},
   "source": [
    "答：要传输范围内的整数 $\\{0,...,7\\}$ ，我们需要 $\\lceil log_3(8) \\rceil=2$。\n",
    "\n",
    "对于电子设备，有三个条件：正电压、负电压、物理导线中的零电压，这可以很容易地用作三层三元。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddcafd",
   "metadata": {},
   "source": [
    "##### 4. The [Bradley--Terry model](https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model) uses a logistic model to capture preferences. For a user to choose between apples and oranges one assumes scores $o_{\\textrm{apple}}$ and $o_{\\textrm{orange}}$. Our requirements are that larger scores should lead to a higher likelihood in choosing the associated item and that the item with the largest score is the most likely one to be chosen.\n",
    "\n",
    "1. Prove that softmax satisfies this requirement.\n",
    "2. What happens if you want to allow for a default option of choosing neither apples nor oranges? Hint: now the user has three choices.\n",
    "\n",
    "**布拉德利-特里模型使用逻辑模型来捕捉偏好。为了让用户在苹果和橙子之间进行选择，假设分数为 $o_{\\textrm{apple}}$ 和 $o_{\\textrm{orange}}$ 。我们的要求是，较大的分数应该导致选择相关项目的可能性更高，并且分数最大的项目是最有可能被选择的。**\n",
    "\n",
    "1. 证明 softmax 满足此要求。\n",
    "2. 如果您想允许一个默认选项，即选择既不选择苹果也不选择橙子，会发生什么？提示：现在用户有三个选择。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d75e03",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "以下是对上述问题的详细解答：\n",
    "\n",
    "###### 1. 证明 softmax 满足要求\n",
    "\n",
    "Softmax 函数常用于将一组分数转换为表示各个选项概率的分布。对于苹果和橙子这两个选项，对应的分数分别为$o_{\\text{apple}}$和$o_{\\text{orange}}$，使用 softmax 函数来计算选择苹果和橙子的概率分别如下：\n",
    "\n",
    "选择苹果的概率$P(\\text{apple})$为：\n",
    "\n",
    "$$P(\\text{apple})=\\frac{e^{o_{\\text{apple}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}}$$\n",
    "\n",
    "选择橙子的概率$P(\\text{orange})$为：\n",
    "\n",
    "$$P(\\text{orange})=\\frac{e^{o_{\\text{orange}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}}$$\n",
    "\n",
    "为了证明较大的分数会导致选择相关项目的可能性更高，我们可以对概率关于对应的分数求偏导数来分析其单调性。\n",
    "\n",
    "首先对$P(\\text{apple})$关于$o_{\\text{apple}}$求偏导数：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial P(\\text{apple})}{\\partial o_{\\text{apple}}}&=\\frac{e^{o_{\\text{apple}}}(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}})-e^{o_{\\text{apple}}}e^{o_{\\text{apple}}}}{(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}})^2}\\\\\n",
    "&=\\frac{e^{o_{\\text{apple}}}e^{o_{\\text{orange}}}}{(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}})^2}>0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "这表明随着$o_{\\text{apple}}$的增大，选择苹果的概率$P(\\text{apple})$会增大。\n",
    "\n",
    "同理，对$P(\\text{orange})$关于$o_{\\text{orange}}$求偏导数：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial P(\\text{orange})}{\\partial o_{\\text{orange}}}&=\\frac{e^{o_{\\text{orange}}}(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}})-e^{o_{\\text{orange}}}e^{o_{\\text{orange}}}}{(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}})^2}\\\\\n",
    "&=\\frac{e^{o_{\\text{apple}}}e^{o_{\\text{orange}}}}{(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}})^2}>0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "即随着$o_{\\text{orange}}$的增大，选择橙子的概率$P(\\text{orange})$会增大。\n",
    "\n",
    "此外，如果$o_{\\text{apple}} > o_{\\text{orange}}$，则：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\text{apple})&=\\frac{e^{o_{\\text{apple}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}}\\\\\n",
    "&=\\frac{1}{1 + e^{-(o_{\\text{apple}} - o_{\\text{orange}})}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\text{orange})&=\\frac{e^{o_{\\text{orange}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}}\\\\\n",
    "&=\\frac{1}{1 + e^{-(o_{\\text{orange}} - o_{\\text{apple}})}}=\\frac{1}{1 + e^{(o_{\\text{apple}} - o_{\\text{orange}})}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "因为$o_{\\text{apple}} > o_{\\text{orange}}$，所以$e^{-(o_{\\text{apple}} - o_{\\text{orange}})}< 1$ 且 $e^{(o_{\\text{apple}} - o_{\\text{orange}})}> 1$，从而有$P(\\text{apple}) > P(\\text{orange})$，即分数最大的项目是最有可能被选择的。所以 softmax 函数满足要求。\n",
    "\n",
    "###### 2. 加入默认选项（第三个选择）时的情况\n",
    "\n",
    "当加入一个既不选择苹果也不选择橙子的默认选项后，现在总共有三个选择，假设默认选项对应的分数为$o_{\\text{default}}$。\n",
    "\n",
    "使用 softmax 函数来计算选择苹果、橙子和默认选项的概率分别如下：\n",
    "\n",
    "选择苹果的概率$P(\\text{apple})$为：\n",
    "\n",
    "$$P(\\text{apple})=\\frac{e^{o_{\\text{apple}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}+e^{o_{\\text{default}}}}$$\n",
    "\n",
    "选择橙子的概率$P(\\text{orange})$为：\n",
    "\n",
    "$$P(\\text{orange})=\\frac{e^{o_{\\text{orange}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}+e^{o_{\\text{default}}}}$$\n",
    "\n",
    "选择默认选项的概率$P(\\text{default})$为：\n",
    "\n",
    "$$P(\\text{default})=\\frac{e^{o_{\\text{default}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}+e^{o_{\\text{default}}}}$$\n",
    "\n",
    "同样地，我们可以分别对这些概率关于各自对应的分数求偏导数来分析单调性。例如对$P(\\text{apple})$关于$o_{\\text{apple}}$求偏导数：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial P(\\text{apple})}{\\partial o_{\\text{apple}}}&=\\frac{e^{o_{\\text{apple}}}(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}+e^{o_{\\text{default}}})-e^{o_{\\text{apple}}}e^{o_{\\text{apple}}}}{(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}+e^{o_{\\text{default}}})^2}\\\\\n",
    "&=\\frac{e^{o_{\\text{apple}}}(e^{o_{\\text{orange}}}+e^{o_{\\text{default}}})}{(e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}+e^{o_{\\text{default}}})^2}>0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "这意味着随着$o_{\\text{apple}}$增大，选择苹果的概率依然会增大，同理对于橙子和默认选项对应的分数也有类似的性质。\n",
    "\n",
    "并且如果$o_{\\text{apple}}$是三个分数中最大的，即$o_{\\text{apple}} > o_{\\text{orange}}$且$o_{\\text{apple}} > o_{\\text{default}}$，那么：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\text{apple})&=\\frac{e^{o_{\\text{apple}}}}{e^{o_{\\text{apple}}}+e^{o_{\\text{orange}}}+e^{o_{\\text{default}}}}\\\\\n",
    "&=\\frac{1}{1 + \\frac{e^{o_{\\text{orange}}}}{e^{o_{\\text{apple}}}}+\\frac{e^{o_{\\text{default}}}}{e^{o_{\\text{apple}}}}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "因为$\\frac{e^{o_{\\text{orange}}}}{e^{o_{\\text{apple}}}}< 1$ 且 $\\frac{e^{o_{\\text{default}}}}{e^{o_{\\text{apple}}}}< 1$，所以$P(\\text{apple})$会大于$P(\\text{orange})$和$P(\\text{default})$，即分数最大的项目仍然是最有可能被选择的。\n",
    "\n",
    "不过，加入默认选项后，整体的概率分布需要重新调整，而且选择不做前两者选择（即选择默认选项）的概率也会随着其对应分数$o_{\\text{default}}$的变化而变化，并且会影响到选择苹果和橙子的相对概率情况，使得整个选择概率模型变得更加复杂，需要综合考虑三个分数之间的关系来分析具体的选择倾向。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67788d01",
   "metadata": {},
   "source": [
    "##### 5. Softmax gets its name from the following mapping: $\\textrm{RealSoftMax}(a, b) = \\log (\\exp(a) + \\exp(b))$.\n",
    "\n",
    "1. Prove that $\\textrm{RealSoftMax}(a, b) > \\mathrm{max}(a, b)$.\n",
    "2. How small can you make the difference between both functions? Hint: without loss of generality you can set $b = 0$ and $a \\geq b$.\n",
    "3. Prove that this holds for $\\lambda^{-1} \\textrm{RealSoftMax}(\\lambda a, \\lambda b)$, provided that $\\lambda > 0$.\n",
    "4. Show that for $\\lambda \\to \\infty$ we have $\\lambda^{-1} \\textrm{RealSoftMax}(\\lambda a, \\lambda b) \\to \\mathrm{max}(a, b)$.\n",
    "5. Construct an analogous softmin function.\n",
    "6. Extend this to more than two numbers.\n",
    "\n",
    "**Softmax 的名称来源于以下映射： $\\textrm{RealSoftMax}(a, b) = \\log (\\exp(a) + \\exp(b))$ ：**\n",
    "\n",
    "1. 证明 $\\textrm{RealSoftMax}(a, b) > \\mathrm{max}(a, b)$ 。\n",
    "2. 你能把这两个函数之间的差异缩小到多小？提示：在不失一般性的情况下，你可以设置 $b = 0$ 和 $a \\geq b$ 。\n",
    "3. 证明在 $\\lambda > 0$ 的前提下，这对 $\\lambda^{-1} \\textrm{RealSoftMax}(\\lambda a, \\lambda b)$ 成立。\n",
    "4. 显示对于 $\\lambda \\to \\infty$ 我们有 $\\lambda^{-1} \\textrm{RealSoftMax}(\\lambda a, \\lambda b) \\to \\mathrm{max}(a, b)$ 。\n",
    "5. 构造一个类似的 softmin 函数。\n",
    "6. 将此扩展到两个以上的数字。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247db753",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1. 假定 $a \\geq b$:\n",
    "   $$log(exp(a)+exp(b)) \\geq log(exp(a)) = a = max(a, b)$$\n",
    "2. 假定 $a \\geq b, b \\geq 0$:\n",
    "   $$diff = log(exp(a) + exp(b)) - a >= log(exp(a) + 1) - a$$\n",
    "3. 假定 $a \\geq b$, then \\lambda a \\geq \\lambda b$:\n",
    "   $$\\lambda^{-1} log(exp(\\lambda a)+exp(\\lambda b)) \\geq \\lambda^{-1} log(exp( \\lambda a)) = a = max(a, b)$$\n",
    "4. 假定 $a \\geq b, b = 0$: $$diff = \\lambda^{-1} log(exp(\\lambda a)+exp(\\lambda b)) - a =\\lambda^{-1} log (exp(\\lambda a)+ 1) - a$$\n",
    "   $$\\lim_{\\lambda \\to \\infty} diff = \\lim_{\\lambda \\to \\infty} \\frac{log(1+exp(-\\lambda a))}{\\lambda}=0 $$\n",
    "5. $$RealSoftMin(a, b) = -log(exp(-a)+exp(-b))$$\n",
    "6. $$RealSoftMax(a_1, a_2, ... a_n) =log( \\sum_{i=0}^n exp(a_i))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa7a8e",
   "metadata": {},
   "source": [
    "##### 6. The function $g(\\mathbf{x}) \\stackrel{\\textrm{def}}{=} \\log \\sum_i \\exp x_i$ is sometimes also referred to as the [log-partition function](<https://en.wikipedia.org/wiki/Partition_function_(mathematics)>).\n",
    "\n",
    "1. Prove that the function is convex. Hint: to do so, use the fact that the first derivative amounts to the probabilities from the softmax function and show that the second derivative is the variance.\n",
    "2. Show that $g$ is translation invariant, i.e., $g(\\mathbf{x} + b) = g(\\mathbf{x})$.\n",
    "3. What happens if some of the coordinates $x_i$ are very large? What happens if they're all very small?\n",
    "4. Show that if we choose $b = \\mathrm{max}_i x_i$ we end up with a numerically stable implementation.\n",
    "\n",
    "**函数 $g(\\mathbf{x}) \\stackrel{\\textrm{def}}{=} \\log \\sum_i \\exp x_i$ 有时也被称为对数分区函数。**\n",
    "\n",
    "1. 证明该函数是凸的。提示：为此，利用第一个导数等于 softmax 函数的概率，并证明第二个导数是方差。\n",
    "2. 显示 $g$ 是平移不变的，即 $g(\\mathbf{x} + b) = g(\\mathbf{x})$ 。\n",
    "3. 如果某些坐标 $x_i$ 非常大，会发生什么？如果它们都非常小，会发生什么？\n",
    "4. 显示如果我们选择 $b = \\mathrm{max}_i x_i$ ，我们最终会得到一个数值稳定的实现。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcf943",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1. $$\\partial_{x_i} g(\\mathbf{x}) = \\frac{exp(x_i)}{\\sum_i exp (x_i)}$$\n",
    "   所以 $g'(\\mathbf{x}) = softmax(\\mathbf{x})$\n",
    "   $$\\frac{\\partial^2 g(\\mathbf{x})}{\\partial x_i^2} = \\frac{exp(x_i)\\sum_i exp(x_i) - (exp(x_i))^2}{(\\sum_i exp (x_i))^2} = softmax(\\mathbf{x})_i(1 - softmax(\\mathbf{x})_i)$$\n",
    "   所以 $g''(x) > 0$ ，该函数是凸的。\n",
    "2. $$g(x+b) = log \\sum_i exp(x_i + b) = log \\sum_i exp(x_i) exp(b) = log exp(b) \\sum_i exp(x) = g(x) + b$$\n",
    "3. 如果某些 $x_i$ 非常大，相应的 $exp(x_i)$ 项可能会大于我们对于某些数据类型可以拥有的最大数字。这可能导致溢出。如果所有 $x_i$ 都是非常大的负数，对应的 $exp(x_i)$ 项将接近于零。如果它小于数据类型可以表示的最小正数，将导致下溢。分母将变为 0。\n",
    "4. $$g(x) = g(x - max_i x_i) + max_i x_i$$\n",
    "   此形式确保从所有 $x_i$ 中减去最大值 b，从而减少由于大指数导致的数值不稳定性。这在实践中常用于提高计算 g(x) 的数值稳定性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9672f7",
   "metadata": {},
   "source": [
    "##### 7. Assume that we have some probability distribution $P$. Suppose we pick another distribution $Q$ with $Q(i) \\propto P(i)^\\alpha$ for $\\alpha > 0$.\n",
    "\n",
    "1. Which choice of $\\alpha$ corresponds to doubling the temperature? Which choice corresponds to halving it?\n",
    "2. What happens if we let the temperature approach $0$?\n",
    "3. What happens if we let the temperature approach $\\infty$?\n",
    "\n",
    "**假设我们有一些概率分布 $P$ 。假设我们选择另一个分布 $Q$ ，其 $Q(i) \\propto P(i)^\\alpha$ 用于 $\\alpha > 0$ 。**\n",
    "\n",
    "1. 哪个 $\\alpha$ 的选择对应于将温度加倍？哪个选择对应于将其减半？\n",
    "2. 如果我们让温度接近 $0$ 会发生什么？\n",
    "3. 如果我们让温度接近 $\\infty$ 会发生什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d1fbc",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1. $$P(i) = \\frac{exp(x_i / T_p)}{\\sum_i exp(x_i / T_p)}, Q(i) = \\frac{exp(x_i / T_q)}{\\sum_i exp(x_i / T_q)}$$\n",
    "   $$\\frac{Q(i)}{Q(j)} = \\left(\\frac{P(i)}{P(j)}\\right)^\\alpha $$\n",
    "   因此：\n",
    "   $$exp(\\frac{x_i-x_j}{T_q})=exp(\\frac{\\alpha(x_i-x_j)}{T_p})$$\n",
    "   $$\\frac{T_p}{T_q} = \\alpha$$\n",
    "   $$T_q = 2 T_p: \\alpha = 1/2$$\n",
    "   $$T_q = T_p / 2: \\alpha = 2$$\n",
    "2. 如果 $T \\to 0$ ，具有最大值的指数项将主导分母，所有其他项将趋近于 0。softmax 函数将把所有概率质量分配给最大元素，而将其他元素的概率分配为零。\n",
    "3. 如果 $T \\to \\infty$，$x_i / T \\to 0$，$exp(x_i / T) \\to 1$：$P(i) \\to \\frac{1}{n}$ 。则它将变成一个均匀分布。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
