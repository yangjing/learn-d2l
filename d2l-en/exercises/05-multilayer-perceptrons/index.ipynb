{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Multiplayer Perceptrons\n",
    "\n",
    "**多层感知机**\n",
    "\n",
    "[5-3](5-3.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $l_2$ 正则化\n",
    "\n",
    "在机器学习中，为了防止过拟合现象的发生，我们通常会对模型进行正则化。其中一种常见的正则化方法就是 L2 正则化。\n",
    "\n",
    "L2 正则化的定义如下：给定超参数 λ，正则化项为模型参数的平方和乘以 λ 的一半。具体来说，假设我们的模型有 n 个参数 θ1, θ2, ..., θn，则 L2 正则化的损失函数可以表示为：\n",
    "\n",
    "$J(θ) = MSE(y, ŷ) + λ/2 * ||θ||^2$\n",
    "\n",
    "其中 $MSE(y, ŷ)$ 是我们所使用的损失函数（如均方误差），$y$ 是真实标签，$ŷ$ 是模型预测值；$||θ||^2$ 表示模型参数的平方和，即 $θ1^2 + θ2^2 + ... + θn^2$。\n",
    "\n",
    "通过加入 $L_2$ 正则化项，我们可以限制模型参数的大小，从而避免过拟合问题的发生。具体而言，当 λ 越大时，正则化项对损失函数的影响就越大，模型参数也就越小，模型的泛化能力就越强。因此，在实际应用中，我们需要根据具体情况选择合适的 λ 值来进行正则化处理。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
