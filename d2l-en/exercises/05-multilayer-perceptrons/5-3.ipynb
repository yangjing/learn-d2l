{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.6. Exercises\n",
    "\n",
    "<https://d2l.ai/chapter_multilayer-perceptrons/backprop.html#exercises>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from d2l import torch as d2l\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Assume that the inputs $\\mathbf{X}$ to some scalar function $f$ are $n \\times m$ matrices. What is the dimensionality of the gradient of $f$ with respect to $\\mathbf{X}$?\n",
    "\n",
    "**假设输入 $\\mathbf{X}$ 到某个标量函数 $f$ 是 $n \\times m$ 矩阵。 那么 $f$ 相对于 $\\mathbf{X}$ 的梯度的维度是多少？**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：该梯度的维度为： $n \\times m$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Add a bias to the hidden layer of the model described in this section (you do not need to include bias in the regularization term).\n",
    "\n",
    "1. Draw the corresponding computational graph.\n",
    "2. Derive the forward and backward propagation equations.\n",
    "\n",
    "**在本节中为模型的隐藏层添加一个偏置（您不需要在正则化项中包含偏置）。**\n",
    "\n",
    "1. 绘制相应的计算图。\n",
    "2. 推导前向传播和后向传播方程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1. 计算图\n",
    "   ![image.png](5_3_1.png)\n",
    "2. 方程\n",
    "\n",
    "   前向传播\n",
    "   $$\\mathbf{z}= \\mathbf{W}^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)}$$\n",
    "   $$\\mathbf{h}= \\phi (\\mathbf{z}).$$\n",
    "   $$\\mathbf{o}= \\mathbf{W}^{(2)} \\mathbf{h} + \\mathbf{b}^{(2)}$$\n",
    "   $$L = l(\\mathbf{o}, y).$$\n",
    "   $$J = L + s.$$\n",
    "\n",
    "   反向传播\n",
    "   $$\\frac{\\partial J}{\\partial L} = 1 \\; \\textrm{and} \\; \\frac{\\partial J}{\\partial s} = 1.$$\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial J}{\\partial \\mathbf{o}}\n",
    "   = \\textrm{prod}\\left(\\frac{\\partial J}{\\partial L}, \\frac{\\partial L}{\\partial \\mathbf{o}}\\right)\n",
    "   = \\frac{\\partial L}{\\partial \\mathbf{o}}\n",
    "   \\in \\mathbb{R}^q.\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial J}{\\partial \\mathbf{b}^{(2)}}= \\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{o}}, \\frac{\\partial \\mathbf{o}}{\\partial \\mathbf{b}^{(2)}}\\right) = \\frac{\\partial L}{\\partial \\mathbf{o}}\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial s}{\\partial \\mathbf{W}^{(1)}} = \\lambda \\mathbf{W}^{(1)}\n",
    "   \\; \\textrm{and} \\;\n",
    "   \\frac{\\partial s}{\\partial \\mathbf{W}^{(2)}} = \\lambda \\mathbf{W}^{(2)}.\n",
    "   $$\n",
    "\n",
    "   $$\\frac{\\partial J}{\\partial \\mathbf{W}^{(2)}}= \\frac{\\partial J}{\\partial \\mathbf{o}} \\mathbf{h}^\\top + \\lambda \\mathbf{W}^{(2)}.$$\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial J}{\\partial \\mathbf{h}}\n",
    "   = \\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{o}}, \\frac{\\partial \\mathbf{o}}{\\partial \\mathbf{h}}\\right)\n",
    "   = {\\mathbf{W}^{(2)}}^\\top \\frac{\\partial J}{\\partial \\mathbf{o}}.\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial J}{\\partial \\mathbf{z}}\n",
    "   = \\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{h}}, \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{z}}\\right)\n",
    "   = \\frac{\\partial J}{\\partial \\mathbf{h}} \\odot \\phi'\\left(\\mathbf{z}\\right).\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial J}{\\partial \\mathbf{b}^{(1)}}=\\textrm{prod}\\left(\\frac{\\partial J}{\\partial \\mathbf{z}}, \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{b}^{(1)}}\\right)\n",
    "   =\\frac{\\partial J}{\\partial \\mathbf{h}} \\odot \\phi'\\left(\\mathbf{z}\\right)\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial J}{\\partial \\mathbf{W}^{(1)}}\n",
    "   = \\frac{\\partial J}{\\partial \\mathbf{z}} \\mathbf{x}^\\top + \\lambda \\mathbf{W}^{(1)}.\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Compute the memory footprint for training and prediction in the model described in this section.\n",
    "\n",
    "**计算本节中所述模型的训练和预测的内存占用。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjing/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# 答\n",
    "\n",
    "\n",
    "class MLP(d2l.Classifier):\n",
    "  def __init__(self, num_outputs, num_hiddens, lr, plot_flag=True):\n",
    "    super().__init__()\n",
    "    self.save_hyperparameters()\n",
    "    self.net = nn.Sequential(\n",
    "      nn.Flatten(), nn.LazyLinear(num_hiddens), nn.ReLU(), nn.LazyLinear(num_outputs)\n",
    "    )\n",
    "\n",
    "  def training_step(self, batch):\n",
    "    l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "    if self.plot_flag:\n",
    "      self.plot(\"loss\", l, train=True)\n",
    "    return l\n",
    "\n",
    "  def validation_step(self, batch):\n",
    "    Y_hat = self(*batch[:-1])\n",
    "    l = self.loss(Y_hat, batch[-1])\n",
    "    if self.plot_flag:\n",
    "      self.plot(\"loss\", self.loss(Y_hat, batch[-1]), train=False)\n",
    "      self.plot(\"acc\", self.accuracy(Y_hat, batch[-1]), train=False)\n",
    "    return l\n",
    "\n",
    "\n",
    "model = MLP(num_outputs=10, num_hiddens=256, lr=0.1, plot_flag=False)\n",
    "data = d2l.FashionMNIST(batch_size=256)\n",
    "trainer = d2l.Trainer(max_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-12-24 17:49:10 17061:4014684 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "STAGE:2024-12-24 17:49:13 17061:4014684 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2024-12-24 17:49:13 17061:4014684 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        83.39%        2.742s        83.42%        2.743s       9.902ms     209.92 Mb     209.46 Mb           277  \n",
      "                                     aten::resolve_conj         0.00%       4.000us         0.00%       4.000us       0.001us     129.05 Mb     129.05 Mb          2747  \n",
      "                                               aten::mm         0.94%      30.922ms         0.94%      30.922ms      43.861us     240.81 Mb     111.76 Mb           705  \n",
      "                                        aten::clamp_min         0.21%       6.755ms         0.21%       6.755ms      24.564us      68.36 Mb      68.36 Mb           275  \n",
      "                                            aten::addmm         2.25%      74.002ms         2.45%      80.414ms     146.207us      71.01 Mb      59.84 Mb           550  \n",
      "                               aten::threshold_backward         0.20%       6.550ms         0.20%       6.550ms      27.872us      57.84 Mb      57.84 Mb           235  \n",
      "                                           aten::expand         0.02%     515.000us         0.02%     528.000us       0.960us      11.17 Mb      11.17 Mb           550  \n",
      "                                     aten::_log_softmax         0.25%       8.198ms         0.25%       8.198ms      29.811us       2.67 Mb       2.67 Mb           275  \n",
      "                                           aten::linear         0.12%       4.012ms         2.53%      83.262ms     151.385us      71.01 Mb       2.28 Mb           550  \n",
      "                       aten::_log_softmax_backward_data         0.16%       5.194ms         0.16%       5.194ms      22.102us       2.09 Mb       2.09 Mb           235  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.288s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "  with record_function(\"model_train\"):\n",
    "    trainer.fit(model, data)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "     aten::empty_strided         0.04%      25.000us         0.04%      25.000us      25.000us     179.44 Mb     179.44 Mb             1  \n",
      "             aten::addmm        38.11%      22.907ms        50.37%      30.276ms      15.138ms      60.88 Mb      60.88 Mb             2  \n",
      "         aten::clamp_min        13.42%       8.065ms        13.42%       8.065ms       8.065ms      58.59 Mb      58.59 Mb             1  \n",
      "                aten::to         0.01%       7.000us        29.15%      17.518ms      17.518ms     179.44 Mb           0 b             1  \n",
      "          aten::_to_copy         0.02%      14.000us        29.13%      17.511ms      17.511ms     179.44 Mb           0 b             1  \n",
      "             aten::copy_        41.32%      24.837ms        41.32%      24.837ms       8.279ms           0 b           0 b             3  \n",
      "           aten::flatten         0.01%       8.000us         0.02%      15.000us      15.000us           0 b           0 b             1  \n",
      "    aten::_reshape_alias         0.01%       7.000us         0.01%       7.000us       7.000us           0 b           0 b             1  \n",
      "            aten::linear         0.02%      13.000us        50.45%      30.322ms      15.161ms      60.88 Mb           0 b             2  \n",
      "                 aten::t         0.03%      19.000us         0.05%      33.000us      16.500us           0 b           0 b             2  \n",
      "------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 60.105ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-12-24 17:49:15 17061:4014684 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2024-12-24 17:49:15 17061:4014684 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2024-12-24 17:49:15 17061:4014684 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "  with record_function(\"model_infer\"):\n",
    "    model(data.train.data.type(torch.float32))\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Assume that you want to compute second derivatives. What happens to the computational graph? How long do you expect the calculation to take?\n",
    "\n",
    "**假设您想计算二阶导数。计算图会发生什么变化？您预计计算将花费多长时间？**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1. 计算图变得更深更复杂，因为它不仅需要捕捉参数与损失之间的关系，还需要捕捉梯度与其梯度之间的关系。\n",
    "2. 假设我们在一个网络中有 N 个参数，损失是一个标量。第一导数有 N 个元素。但第二导数有 N^2 个元素。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Assume that the computational graph is too large for your GPU.\n",
    "\n",
    "1. Can you partition it over more than one GPU?\n",
    "2. What are the advantages and disadvantages over training on a smaller minibatch?\n",
    "\n",
    "**假设计算图对于你的 GPU 来说太大。**\n",
    "\n",
    "1. 你能在多个 GPU 上进行分区吗？\n",
    "2. 在较小的迷你批次上训练的优缺点是什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1.  我们可以在多个 GPU 上拆分模型或小批量数据。\n",
    "2.  迷你批次上训练\n",
    "    - 优点：它允许我们处理更大的模型或数据集，这些模型或数据集无法容纳在单个 GPU 的内存中。由于并行计算，它可以导致更快的训练时间。\n",
    "    - 缺点：在 GPU 之间交换信息时会有通信开销，这可能会减慢训练速度。同步多个 GPU 可能很复杂，尤其是在处理异步更新时。较小的迷你批次可能导致更嘈杂的梯度估计，从而减慢收敛速度。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
