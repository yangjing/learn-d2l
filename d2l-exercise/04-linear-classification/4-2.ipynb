{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.5. Exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.use_svg_display()\n",
    "\n",
    "\n",
    "class FashionMNIST(d2l.DataModule):  # @save\n",
    "  \"\"\"The Fashion-MNIST dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, batch_size=64, resize=(28, 28)):\n",
    "    super().__init__()\n",
    "    self.save_hyperparameters()\n",
    "    trans = transforms.Compose([transforms.Resize(resize), transforms.ToTensor()])\n",
    "    self.train = torchvision.datasets.FashionMNIST(\n",
    "      root=self.root, train=True, transform=trans, download=True\n",
    "    )\n",
    "    self.val = torchvision.datasets.FashionMNIST(\n",
    "      root=self.root, train=False, transform=trans, download=True\n",
    "    )\n",
    "\n",
    "  def text_labels(self, indices):\n",
    "    \"\"\"Return text labels.\"\"\"\n",
    "    labels = [\n",
    "      \"t-shirt\",\n",
    "      \"trouser\",\n",
    "      \"pullover\",\n",
    "      \"dress\",\n",
    "      \"coat\",\n",
    "      \"sandal\",\n",
    "      \"shirt\",\n",
    "      \"sneaker\",\n",
    "      \"bag\",\n",
    "      \"ankle boot\",\n",
    "    ]\n",
    "    return [labels[int(i)] for i in indices]\n",
    "\n",
    "  def get_dataloader(self, train):\n",
    "    data = self.train if train else self.val\n",
    "    return torch.utils.data.DataLoader(\n",
    "      data, self.batch_size, shuffle=train, num_workers=self.num_workers\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FashionMNIST(resize=(32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_time(data):\n",
    "  tic = time.time()\n",
    "  for X, y in data.train_dataloader():\n",
    "    continue\n",
    "  return time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Does reducing the `batch_size` (for instance, to 1) affect the reading performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：当批量大小减少时，每次迭代中一起处理的示例数量会减少。这可能导致数据加载和预处理操作的频率增加，从而可能增加时间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.81 sec'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{load_time(FashionMNIST(batch_size=64, resize=(32, 32))):.2f} sec\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.05 sec'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{load_time(FashionMNIST(batch_size=1, resize=(32, 32))):.2f} sec\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. The data iterator performance is important. Do you think the current implementation is fast enough? Explore various options to improve it. Use a system profiler to find out where the bottlenecks are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：改进的方法：使用多线程并行加载数据，使用高效的数据格式\n",
    "\n",
    "_在 Mac M1 Max 上，`{method 'poll' of 'select.poll' objects}` 花了最多的时间_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         203749 function calls (203743 primitive calls) in 1.920 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      942    1.634    0.002    1.634    0.002 {method 'poll' of 'select.poll' objects}\n",
      "     1876    0.058    0.000    0.058    0.000 {built-in method _new_shared_filename_cpu}\n",
      "        1    0.043    0.043    1.920    1.920 2229652835.py:1(load_time)\n",
      "        4    0.017    0.004    0.017    0.004 {built-in method _posixsubprocess.fork_exec}\n",
      "      938    0.015    0.000    0.115    0.000 {built-in method _pickle.loads}\n",
      "     1876    0.009    0.000    0.009    0.000 {built-in method torch.tensor}\n",
      "      939    0.009    0.000    0.009    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "        8    0.009    0.001    0.009    0.001 {method '_share_filename_cpu_' of 'torch._C.StorageBase' objects}\n",
      "     1876    0.007    0.000    0.007    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
      "      940    0.006    0.000    0.010    0.000 sampler.py:241(__iter__)\n",
      "      938    0.005    0.000    1.592    0.002 queues.py:98(get)\n",
      "      939    0.005    0.000    0.005    0.000 {built-in method torch._ops.profiler.}\n",
      "     1876    0.004    0.000    0.074    0.000 reductions.py:319(rebuild_storage_filename)\n",
      "      939    0.004    0.000    1.836    0.002 dataloader.py:628(__next__)\n",
      "      942    0.004    0.000    1.638    0.002 selectors.py:403(select)\n",
      "     1876    0.004    0.000    0.004    0.000 {built-in method posix.read}\n",
      "      939    0.003    0.000    1.811    0.002 dataloader.py:1298(_next_data)\n",
      "      942    0.003    0.000    1.649    0.002 connection.py:917(wait)\n",
      "     1884    0.003    0.000    0.006    0.000 reductions.py:69(__setitem__)\n",
      "      939    0.003    0.000    0.008    0.000 profiler.py:495(__exit__)\n",
      "    60001    0.003    0.000    0.005    0.000 sampler.py:117(__iter__)\n",
      "     1884    0.003    0.000    0.003    0.000 reductions.py:28(__init__)\n",
      "     1876    0.002    0.000    0.020    0.000 reductions.py:98(rebuild_tensor)\n",
      "     1876    0.002    0.000    0.006    0.000 reductions.py:339(rebuild_typed_storage)\n",
      "     1888    0.002    0.000    0.002    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "      946    0.002    0.000    0.021    0.000 dataloader.py:1347(_try_put_index)\n",
      "     1876    0.002    0.000    0.006    0.000 connection.py:374(_recv)\n",
      "     1018    0.002    0.000    0.002    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "      942    0.002    0.000    0.008    0.000 queues.py:86(put)\n",
      "      953    0.002    0.000    0.002    0.000 {method 'release' of '_thread.lock' objects}\n",
      "     1881    0.002    0.000    0.002    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "     1876    0.002    0.000    0.017    0.000 _utils.py:145(_rebuild_tensor)\n",
      "     1876    0.002    0.000    0.002    0.000 reductions.py:65(get)\n",
      "     1884    0.002    0.000    0.002    0.000 storage.py:355(__new__)\n",
      "      942    0.001    0.000    0.003    0.000 selectors.py:235(register)\n",
      "      938    0.001    0.000    0.008    0.000 connection.py:413(_recv_bytes)\n",
      "     1884    0.001    0.000    0.002    0.000 storage.py:427(__init__)\n",
      "      938    0.001    0.000    1.458    0.002 connection.py:423(_poll)\n",
      "      939    0.001    0.000    0.002    0.000 profiler.py:482(__init__)\n",
      "      939    0.001    0.000    0.011    0.000 profiler.py:491(__enter__)\n",
      "      938    0.001    0.000    0.010    0.000 connection.py:208(recv_bytes)\n",
      "        2    0.001    0.001    0.001    0.001 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "     1876    0.001    0.000    0.003    0.000 reductions.py:299(storage_from_cache)\n",
      "      942    0.001    0.000    0.005    0.000 selectors.py:352(register)\n",
      "      946    0.001    0.000    0.003    0.000 threading.py:351(notify)\n",
      "        8    0.001    0.000    0.011    0.001 {method 'dump' of '_pickle.Pickler' objects}\n",
      "      942    0.001    0.000    0.002    0.000 selectors.py:348(__init__)\n",
      "      938    0.001    0.000    1.593    0.002 dataloader.py:1119(_try_get_data)\n",
      "       16    0.001    0.000    0.001    0.000 socket.py:626(send)\n",
      "      938    0.001    0.000    0.020    0.000 dataloader.py:1367(_process_data)\n",
      "      938    0.001    0.000    1.459    0.002 connection.py:253(poll)\n",
      "       72    0.001    0.000    0.001    0.000 {built-in method posix.write}\n",
      "      938    0.001    0.000    1.593    0.002 dataloader.py:1265(_get_data)\n",
      "      942    0.001    0.000    0.001    0.000 selectors.py:269(close)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.randperm}\n",
      "      942    0.001    0.000    0.001    0.000 selectors.py:21(_fileobj_to_fd)\n",
      "       16    0.001    0.000    0.002    0.000 reductions.py:75(free_dead_references)\n",
      "8812/8807    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      942    0.001    0.000    0.001    0.000 selectors.py:210(__init__)\n",
      "      939    0.001    0.000    0.001    0.000 typing.py:271(inner)\n",
      "      958    0.000    0.000    0.001    0.000 threading.py:256(__enter__)\n",
      "        4    0.000    0.000    0.030    0.008 popen_spawn_posix.py:38(_launch)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "     4756    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "     2830    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)\n",
      "     5708    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "      939    0.000    0.000    0.009    0.000 _ops.py:497(__call__)\n",
      "       20    0.000    0.000    0.002    0.000 synchronize.py:50(__init__)\n",
      "     1965    0.000    0.000    0.011    0.000 {built-in method builtins.next}\n",
      "      938    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
      "     2851    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x1027d7388}\n",
      "      942    0.000    0.000    0.000    0.000 selectors.py:276(_key_from_fd)\n",
      "     2064    0.000    0.000    0.001    0.000 reductions.py:34(expired)\n",
      "      939    0.000    0.000    0.005    0.000 _ops.py:286(__call__)\n",
      "     1876    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\n",
      "     1884    0.000    0.000    0.000    0.000 {method '_weak_ref' of 'torch._C.StorageBase' objects}\n",
      "      942    0.000    0.000    0.001    0.000 selectors.py:203(__exit__)\n",
      "     1876    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "     1932    0.000    0.000    0.000    0.000 {built-in method _free_weak_ref}\n",
      "        1    0.000    0.000    0.040    0.040 dataloader.py:993(__init__)\n",
      "       28    0.000    0.000    0.000    0.000 util.py:186(__init__)\n",
      "      942    0.000    0.000    0.001    0.000 selectors.py:216(_fileobj_lookup)\n",
      "      958    0.000    0.000    0.000    0.000 threading.py:271(_is_owned)\n",
      "        5    0.000    0.000    0.002    0.000 queues.py:37(__init__)\n",
      "      942    0.000    0.000    0.000    0.000 connection.py:933(<listcomp>)\n",
      "     1876    0.000    0.000    0.000    0.000 connection.py:138(_check_readable)\n",
      "     1880    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      942    0.000    0.000    0.000    0.000 {built-in method select.poll}\n",
      "      958    0.000    0.000    0.000    0.000 threading.py:259(__exit__)\n",
      "      942    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
      "     1876    0.000    0.000    0.000    0.000 {method '_shared_decref' of 'torch._C.StorageBase' objects}\n",
      "     1932    0.000    0.000    0.001    0.000 reductions.py:37(__del__)\n",
      "      160    0.000    0.000    0.000    0.000 random.py:343(choice)\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "     2818    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "        4    0.000    0.000    0.017    0.004 util.py:447(spawnv_passfds)\n",
      "      954    0.000    0.000    0.000    0.000 connection.py:168(fileno)\n",
      "        4    0.000    0.000    0.034    0.009 popen_fork.py:15(__init__)\n",
      "     2064    0.000    0.000    0.000    0.000 {built-in method _expired}\n",
      "      946    0.000    0.000    0.011    0.000 dataloader.py:622(_next_index)\n",
      "        8    0.000    0.000    0.003    0.000 iostream.py:592(flush)\n",
      "      942    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "      958    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "      942    0.000    0.000    0.000    0.000 selectors.py:64(__init__)\n",
      "       16    0.000    0.000    0.001    0.000 iostream.py:259(schedule)\n",
      "     2064    0.000    0.000    0.000    0.000 storage.py:925(_expired)\n",
      "       38    0.000    0.000    0.001    0.000 resource_tracker.py:70(ensure_running)\n",
      "      942    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:567(__init__)\n",
      "        4    0.000    0.000    0.034    0.009 process.py:110(start)\n",
      "        5    0.000    0.000    0.002    0.000 context.py:100(Queue)\n",
      "        4    0.000    0.000    0.004    0.001 util.py:433(_flush_std_streams)\n",
      "     1932    0.000    0.000    0.001    0.000 storage.py:789(_free_weak_ref)\n",
      "        8    0.000    0.000    0.000    0.000 reductions.py:151(reduce_tensor)\n",
      "        5    0.000    0.000    0.000    0.000 queues.py:71(_reset)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "      942    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        4    0.000    0.000    0.001    0.000 spawn.py:150(get_preparation_data)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "       25    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
      "       17    0.000    0.000    0.000    0.000 threading.py:228(__init__)\n",
      "      939    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "        8    0.000    0.000    0.000    0.000 _tensor.py:237(_typed_storage)\n",
      "      941    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:80(__init__)\n",
      "       20    0.000    0.000    0.001    0.000 tempfile.py:149(__next__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
      "      939    0.000    0.000    0.000    0.000 _jit_internal.py:1102(is_scripting)\n",
      "        8    0.000    0.000    0.009    0.001 reductions.py:353(reduce_storage)\n",
      "      942    0.000    0.000    0.000    0.000 selectors.py:200(__enter__)\n",
      "      160    0.000    0.000    0.000    0.000 random.py:237(_randbelow_with_getrandbits)\n",
      "       25    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)\n",
      "      526    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 signal_handling.py:63(handler)\n",
      "      978    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 subprocess.py:282(_args_from_interpreter_flags)\n",
      "      974    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "      939    0.000    0.000    0.000    0.000 __init__.py:89(annotate)\n",
      "       34    0.000    0.000    0.001    0.000 resource_tracker.py:153(_send)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:225(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 module.py:1601(__getattr__)\n",
      "       90    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:398(parent)\n",
      "       12    0.000    0.000    0.002    0.000 threading.py:280(wait)\n",
      "        4    0.000    0.000    0.001    0.000 queues.py:161(_start_thread)\n",
      "       20    0.000    0.000    0.001    0.000 synchronize.py:114(_make_name)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:1358(current_thread)\n",
      "       22    0.000    0.000    0.001    0.000 util.py:205(__call__)\n",
      "        8    0.000    0.000    0.011    0.001 reduction.py:58(dump)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        5    0.000    0.000    0.000    0.000 _tensor.py:904(__len__)\n",
      "        8    0.000    0.000    0.000    0.000 reduction.py:38(__init__)\n",
      "        1    0.000    0.000    1.920    1.920 2156649156.py:6(<module>)\n",
      "       12    0.000    0.000    0.002    0.000 threading.py:563(wait)\n",
      "        2    0.000    0.000    0.193    0.097 dataloader.py:1400(_shutdown_workers)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:802(__init__)\n",
      "       14    0.000    0.000    0.001    0.000 synchronize.py:84(_cleanup)\n",
      "       24    0.000    0.000    0.000    0.000 threading.py:1133(is_alive)\n",
      "       20    0.000    0.000    0.000    0.000 tempfile.py:152(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 connection.py:117(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 connection.py:516(Pipe)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method _multiprocessing.sem_unlink}\n",
      "      148    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
      "       29    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       11    0.000    0.000    0.001    0.000 context.py:65(Lock)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:528(__init__)\n",
      "        4    0.000    0.000    0.034    0.009 context.py:222(_Popen)\n",
      "       25    0.000    0.000    0.000    0.000 weakref.py:348(__new__)\n",
      "        5    0.000    0.000    0.000    0.000 context.py:85(BoundedSemaphore)\n",
      "        4    0.000    0.000    0.193    0.048 popen_fork.py:36(wait)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.waitpid}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:61(_cleanup)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'untyped_storage' of 'torch._C._TensorBase' objects}\n",
      "       44    0.000    0.000    0.000    0.000 synchronize.py:100(__getstate__)\n",
      "       20    0.000    0.000    0.000    0.000 tempfile.py:138(rng)\n",
      "       39    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.000    0.000    0.002    0.002 dataloader.py:1086(_reset)\n",
      "        8    0.000    0.000    0.000    0.000 process.py:344(__reduce__)\n",
      "        8    0.000    0.000    0.000    0.000 queues.py:57(__getstate__)\n",
      "        4    0.000    0.000    0.034    0.009 context.py:281(_Popen)\n",
      "       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)\n",
      "       25    0.000    0.000    0.000    0.000 weakref.py:353(__init__)\n",
      "       20    0.000    0.000    0.001    0.000 resource_tracker.py:145(register)\n",
      "      274    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "       19    0.000    0.000    0.000    0.000 weakref.py:106(remove)\n",
      "        4    0.000    0.000    0.001    0.000 context.py:80(Semaphore)\n",
      "        4    0.000    0.000    0.000    0.000 spawn.py:78(get_command_line)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:98(_get_distributed_settings)\n",
      "       38    0.000    0.000    0.000    0.000 resource_tracker.py:134(_check_alive)\n",
      "       14    0.000    0.000    0.000    0.000 popen_fork.py:24(poll)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:189(name)\n",
      "        2    0.000    0.000    1.920    0.960 interactiveshell.py:3514(run_code)\n",
      "       90    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "       28    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       16    0.000    0.000    0.000    0.000 connection.py:967(reduce_connection)\n",
      "        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "    20/19    0.000    0.000    0.000    0.000 dataloader.py:418(__setattr__)\n",
      "        8    0.000    0.000    0.000    0.000 _weakrefset.py:86(add)\n",
      "        1    0.000    0.000    0.000    0.000 2793697560.py:41(get_dataloader)\n",
      "       80    0.000    0.000    0.000    0.000 context.py:351(get_spawning_popen)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}\n",
      "        4    0.000    0.000    0.193    0.048 process.py:142(join)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.034    0.009 popen_spawn_posix.py:30(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 reduction.py:191(DupFd)\n",
      "        8    0.000    0.000    0.000    0.000 queues.py:153(cancel_join_thread)\n",
      "        4    0.000    0.000    0.000    0.000 ipkernel.py:768(init_closure)\n",
      "       16    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "        4    0.000    0.000    0.000    0.000 os.py:804(fsencode)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "       56    0.000    0.000    0.000    0.000 context.py:357(assert_spawning)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:777(__reduce_ex__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.cpu_count}\n",
      "        5    0.000    0.000    0.000    0.000 mnist.py:152(__len__)\n",
      "       91    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "       38    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "       24    0.000    0.000    0.000    0.000 threading.py:1066(_wait_for_tstate_lock)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:880(start)\n",
      "      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._error_if_any_worker_fails}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:683(is_initialized)\n",
      "        4    0.000    0.000    0.000    0.000 sampler.py:110(num_samples)\n",
      "        1    0.000    0.000    0.040    0.040 dataloader.py:428(__iter__)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)\n",
      "       11    0.000    0.000    0.001    0.000 synchronize.py:161(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:62(get_sharing_strategy)\n",
      "        4    0.000    0.000    0.000    0.000 queues.py:140(close)\n",
      "       44    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:488(check_worker_number_rationality)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:1109(ident)\n",
      "       12    0.000    0.000    0.000    0.000 spawn.py:87(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:612(_reset)\n",
      "       19    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        4    0.000    0.000    0.000    0.000 queues.py:204(_finalize_close)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1229(_make_invoke_excepthook)\n",
      "        8    0.000    0.000    0.000    0.000 storage.py:236(is_cuda)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:142(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 2156649156.py:7(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 context.py:354(set_spawning_popen)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:114(__enter__)\n",
      "       16    0.000    0.000    0.000    0.000 process.py:99(_check_closed)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:261(helper)\n",
      "       14    0.000    0.000    0.000    0.000 resource_tracker.py:149(unregister)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:296(notify_all)\n",
      "        8    0.000    0.000    0.000    0.000 process.py:94(<genexpr>)\n",
      "       27    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1255(user_global_ns)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        8    0.000    0.000    0.000    0.000 _namedtensor_internals.py:10(check_serializing_named_tensor)\n",
      "        4    0.000    0.000    0.000    0.000 spawn.py:132(_check_not_importing_main)\n",
      "        1    0.000    0.000    0.001    0.001 context.py:75(Condition)\n",
      "       16    0.000    0.000    0.000    0.000 popen_spawn_posix.py:34(duplicate_for_child)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:268(_acquire_restore)\n",
      "       20    0.000    0.000    0.000    0.000 context.py:197(get_start_method)\n",
      "       10    0.000    0.000    0.000    0.000 context.py:233(get_context)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:234(ident)\n",
      "        8    0.000    0.000    0.000    0.000 {method '_shared_incref' of 'torch._C.StorageBase' objects}\n",
      "       32    0.000    0.000    0.000    0.000 threading.py:536(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:265(_release_save)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3466(compare)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "        8    0.000    0.000    0.000    0.000 hooks.py:82(warn_if_has_hooks)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:153(is_alive)\n",
      "       28    0.000    0.000    0.000    0.000 process.py:37(current_process)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 dataloader.py:1374(_mark_worker_as_unavailable)\n",
      "        1    0.000    0.000    0.000    0.000 torch.py:244(train_dataloader)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "        5    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:334(set)\n",
      "        4    0.000    0.000    0.001    0.000 synchronize.py:125(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "        4    0.000    0.000    0.000    0.000 context.py:249(get_start_method)\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:327(is_set)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:144(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 popen_spawn_posix.py:17(__init__)\n",
      "        2    0.000    0.000    1.920    0.960 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:95(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1162(daemon)\n",
      "        1    0.000    0.000    0.001    0.001 context.py:90(Event)\n",
      "       21    0.000    0.000    0.000    0.000 context.py:187(get_context)\n",
      "       24    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "       22    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:180(extra_flags)\n",
      "        4    0.000    0.000    0.000    0.000 subprocess.py:272(_optim_args_from_interpreter_flags)\n",
      "        4    0.000    0.000    0.000    0.000 util.py:461(close_fds)\n",
      "       16    0.000    0.000    0.000    0.000 connection.py:158(readable)\n",
      "        4    0.000    0.000    0.000    0.000 resource_tracker.py:66(getfd)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        8    0.000    0.000    0.000    0.000 {method 'has_names' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 synchronize.py:219(__getstate__)\n",
      "       16    0.000    0.000    0.000    0.000 connection.py:163(writable)\n",
      "        5    0.000    0.000    0.000    0.000 _weakrefset.py:39(_remove)\n",
      "        8    0.000    0.000    0.000    0.000 reductions.py:343(reduce_typed_storage)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:226(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)\n",
      "        1    0.000    0.000    0.040    0.040 dataloader.py:383(_get_iterator)\n",
      "        1    0.000    0.000    0.001    0.001 synchronize.py:323(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:270(notify)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:213(authkey)\n",
      "        5    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 dataloader.py:1081(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}\n",
      "       13    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        4    0.000    0.000    0.000    0.000 process.py:205(daemon)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:403(WORLD)\n",
      "        4    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:394(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:1477(__del__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1147(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:7(is_available)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        3    0.000    0.000    0.000    0.000 dataloader.py:443(_auto_collation)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 spawn.py:45(get_executable)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:447(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:390(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:1102(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:360(_close)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:323(default_pg)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1375(cast)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.waitstatus_to_exitcode}\n",
      "        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "# Call the function you want to profile\n",
    "load_time(data)\n",
    "profiler.disable()\n",
    "profiler.print_stats(sort=\"tottime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Check out the framework's online API documentation. Which other datasets are available?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "- 图像分类: Caltech 101 Dataset, Caltech 256 Dataset, Large-scale CelebFaces Attributes (CelebA) Dataset Dataset, CIFAR10 Dataset, CIFAR100 Dataset...\n",
    "- 图像检测或分割: MS Coco Detection Dataset, Cityscapes Dataset, KITTI Dataset...\n",
    "- Optical Flow（光流）\n",
    "- Stereo Matching（立体匹配）\n",
    "- ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
