{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3.5 Exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "class SyntheticRegressionData(d2l.DataModule):  # @save\n",
    "  \"\"\"Synthetic data for linear regression.\"\"\"\n",
    "\n",
    "  def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000, batch_size=32):\n",
    "    super().__init__()\n",
    "    self.save_hyperparameters()\n",
    "    n = num_train + num_val\n",
    "    self.X = torch.randn(n, len(w))\n",
    "    noise = torch.randn(n, 1) * noise\n",
    "    self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What will happen if the number of examples cannot be divided by the batch size. How would you change this behavior by specifying a different argument by using the framework’s API?\n",
    "\n",
    "**如果示例的数量无法被批量大小整除，会发生什么？如何通过使用框架的 API 指定不同的参数来改变这种行为？**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：剩余的示例将形成最后一批，其数量少于批处理大小。如果我们想丢弃这些样本，可以在 `torch.utils.data.DataLoader` 中将 `drop_last` 属性设置为 `True` 。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@d2l.add_to_class(d2l.DataModule)  # @save\n",
    "def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
    "  tensors = tuple(a[indices] for a in tensors)\n",
    "  dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "  # drop_last：如果最后一个 `batch` 的数据量不足 `batch_size`，是否丢弃该 `batch`。\n",
    "  return torch.utils.data.DataLoader(dataset, self.batch_size, shuffle=train, drop_last=True)\n",
    "\n",
    "\n",
    "@d2l.add_to_class(SyntheticRegressionData)  # @save\n",
    "def get_dataloader(self, train):\n",
    "  i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "  return self.get_tensorloader((self.X, self.y), train, i)\n",
    "\n",
    "\n",
    "data = SyntheticRegressionData(w=torch.tensor([2, -3.4]), b=4.2)\n",
    "len(data.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Suppose that we want to generate a huge dataset, where both the size of the parameter vector `w` and the number of examples `num_examples` are large.\n",
    "\n",
    "1. What happens if we cannot hold all data in memory?\n",
    "2. How would you shuffle the data if it is held on disk? Your task is to design an _efficient_ algorithm that does not require too many random reads or writes. Hint: [pseudorandom permutation generators](https://en.wikipedia.org/wiki/Pseudorandom_permutation) allow you to design a reshuffle without the need to store the permutation table explicitly.\n",
    "\n",
    "**假设我们想生成一个巨大的数据集，其中参数向量的大小 `w` 和示例的数量 `num_examples` 都很大。**\n",
    "\n",
    "1. 如果我们无法将所有数据保存在内存中，会发生什么？\n",
    "2. 如果数据存储在磁盘上，你将如何打乱数据？你的任务是设计一个高效的算法，不需要太多的随机读写。提示：[伪随机置换生成器](https://en.wikipedia.org/wiki/Pseudorandom_permutation) 允许你设计一个重新洗牌，而无需显式存储置换表。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "1. 我们无法用非常长的索引列表来打乱数据集。这仍然会占用太多内存。\n",
    "2. 我们可以通过一些方法生成伪随机置换，例如（Naor, M., & Reingold, O. (1999). 关于伪随机置换的构造：Luby–Rackoff 再探）。它可以用来生成索引，而无需存储整个置换表。（我没有仔细研究这种方法）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Implement a data generator that produces new data on the fly, every time the iterator is called.\n",
    "\n",
    "**实现一个数据生成器，每次调用迭代器时动态生成新数据。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9905],\n",
      "        [ 3.7216],\n",
      "        [ 5.5276],\n",
      "        [-0.9841],\n",
      "        [-0.7291],\n",
      "        [ 1.7469],\n",
      "        [-0.7048],\n",
      "        [-4.9208]])\n",
      "tensor([[ 4.4728],\n",
      "        [ 5.1979],\n",
      "        [ 2.3361],\n",
      "        [-0.0912],\n",
      "        [ 3.7196],\n",
      "        [ 4.4336],\n",
      "        [ 5.3565],\n",
      "        [ 9.1002]])\n",
      "tensor([[ 1.2371],\n",
      "        [ 8.8374],\n",
      "        [ 5.5805],\n",
      "        [ 7.0196],\n",
      "        [10.6007],\n",
      "        [ 6.7500],\n",
      "        [-3.8152],\n",
      "        [ 3.0384]])\n"
     ]
    }
   ],
   "source": [
    "@d2l.add_to_class(SyntheticRegressionData)  # @save\n",
    "def data_generator(self):\n",
    "  if not hasattr(self, \"iter\"):\n",
    "    self.iter = iter(self.train_dataloader())\n",
    "  return next(self.iter)\n",
    "\n",
    "\n",
    "data = SyntheticRegressionData(w=torch.tensor([2, -3.4]), b=4.2, batch_size=8)\n",
    "for i in range(3):\n",
    "  X, y = data.data_generator()\n",
    "  print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. How would you design a random data generator that generates the same data each time it is called?\n",
    "\n",
    "**如何设计一个随机数据生成器，使其每次被调用时生成相同的数据？**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0 y= tensor([[ 7.5595],\n",
      "        [ 5.8476],\n",
      "        [ 5.5081],\n",
      "        [ 5.3136],\n",
      "        [10.6649],\n",
      "        [ 5.6983],\n",
      "        [ 7.6880],\n",
      "        [ 8.3617]])\n",
      "Time 1 y= tensor([[ 7.5595],\n",
      "        [ 5.8476],\n",
      "        [ 5.5081],\n",
      "        [ 5.3136],\n",
      "        [10.6649],\n",
      "        [ 5.6983],\n",
      "        [ 7.6880],\n",
      "        [ 8.3617]])\n",
      "Time 2 y= tensor([[ 7.5595],\n",
      "        [ 5.8476],\n",
      "        [ 5.5081],\n",
      "        [ 5.3136],\n",
      "        [10.6649],\n",
      "        [ 5.6983],\n",
      "        [ 7.6880],\n",
      "        [ 8.3617]])\n"
     ]
    }
   ],
   "source": [
    "@d2l.add_to_class(SyntheticRegressionData)  # @save\n",
    "def get_dataloader(self, train):\n",
    "  torch.manual_seed(2)  # set the random seed\n",
    "  i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "  return self.get_tensorloader((self.X, self.y), train, i)\n",
    "\n",
    "\n",
    "data = SyntheticRegressionData(w=torch.tensor([2, -3.4]), b=4.2, batch_size=8)\n",
    "for i in range(3):\n",
    "  X, y = next(iter(data.train_dataloader()))\n",
    "  print(\"Time\", i, \"y=\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
